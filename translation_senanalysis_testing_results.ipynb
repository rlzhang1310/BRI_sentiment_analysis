{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "## translation libraries\n",
    "import translators as ts\n",
    "from googletrans import Translator as gt\n",
    "from deep_translator import GoogleTranslator\n",
    "from translate import Translator as tlr\n",
    "\n",
    "## sentiment analysis libraries\n",
    "import spacy\n",
    "from spacytextblob.spacytextblob import SpacyTextBlob\n",
    "import nltk\n",
    "\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "# nltk.download('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lemmatizer = WordNetLemmatizer()\n",
    "def preprocess_text(text, lemmatizer):\n",
    "    if type(text) == float:\n",
    "        return str(text)\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    filtered_tokens = [token for token in tokens if token not in stopwords.words('english')]\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in filtered_tokens]\n",
    "    processed_text = ' '.join(lemmatized_tokens)\n",
    "    return processed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "## https://www.kaggle.com/datasets/saurabhshahane/twitter-sentiment-dataset\n",
    "twitter_data = pd.read_csv(\"/Users/rlzhang1310/Coding/buntain/twitter_dataset/Twitter_Data.csv\")\n",
    "twitter_data[\"text\"] = twitter_data[\"clean_text\"]\n",
    "twitter_data[\"score\"] = twitter_data[\"category\"]\n",
    "twitter_data = twitter_data.drop([\"clean_text\", \"category\"], axis=1)\n",
    "twitter_data[\"processed_text\"] = twitter_data[\"text\"].apply(preprocess_text, lemmatizer = WordNetLemmatizer())\n",
    "twitter_data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "## nltk sentiment analysis\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "def get_nltk_sentiment(text, analyzer):\n",
    "    scores = analyzer.polarity_scores(text)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "## spacy sentiment analysis\n",
    "en_nlp = spacy.load('en_core_web_sm')\n",
    "en_nlp.add_pipe('spacytextblob')\n",
    "\n",
    "def get_spacy_sentiment(text, en_nlp):\n",
    "    doc = en_nlp(text)\n",
    "    return doc._.blob.polarity   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>score</th>\n",
       "      <th>processed_text</th>\n",
       "      <th>nltk_sentiment</th>\n",
       "      <th>spacy_sentiment</th>\n",
       "      <th>processed_nltk_sentiment</th>\n",
       "      <th>processed_spacy_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>when modi promised “minimum government maximum...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>modi promised “ minimum government maximum gov...</td>\n",
       "      <td>{'neg': 0.065, 'neu': 0.781, 'pos': 0.154, 'co...</td>\n",
       "      <td>-0.300000</td>\n",
       "      <td>{'neg': 0.095, 'neu': 0.682, 'pos': 0.223, 'co...</td>\n",
       "      <td>-0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>talk all the nonsense and continue all the dra...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>talk nonsense continue drama vote modi</td>\n",
       "      <td>{'neg': 0.184, 'neu': 0.816, 'pos': 0.0, 'comp...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>{'neg': 0.351, 'neu': 0.649, 'pos': 0.0, 'comp...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what did just say vote for modi  welcome bjp t...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>say vote modi welcome bjp told rahul main camp...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.772, 'pos': 0.228, 'comp...</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.651, 'pos': 0.349, 'comp...</td>\n",
       "      <td>0.483333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>asking his supporters prefix chowkidar their n...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>asking supporter prefix chowkidar name modi gr...</td>\n",
       "      <td>{'neg': 0.187, 'neu': 0.655, 'pos': 0.158, 'co...</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>{'neg': 0.219, 'neu': 0.479, 'pos': 0.301, 'co...</td>\n",
       "      <td>0.033333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>answer who among these the most powerful world...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>answer among powerful world leader today trump...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.808, 'pos': 0.192, 'comp...</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.763, 'pos': 0.237, 'comp...</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162975</th>\n",
       "      <td>why these 456 crores paid neerav modi not reco...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>456 crore paid neerav modi recovered congress ...</td>\n",
       "      <td>{'neg': 0.081, 'neu': 0.919, 'pos': 0.0, 'comp...</td>\n",
       "      <td>-0.291667</td>\n",
       "      <td>{'neg': 0.104, 'neu': 0.896, 'pos': 0.0, 'comp...</td>\n",
       "      <td>-0.291667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162976</th>\n",
       "      <td>dear rss terrorist payal gawar what about modi...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>dear r terrorist payal gawar modi killing 1000...</td>\n",
       "      <td>{'neg': 0.398, 'neu': 0.491, 'pos': 0.111, 'co...</td>\n",
       "      <td>-0.195833</td>\n",
       "      <td>{'neg': 0.435, 'neu': 0.443, 'pos': 0.123, 'co...</td>\n",
       "      <td>-0.246875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162977</th>\n",
       "      <td>did you cover her interaction forum where she ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>cover interaction forum left</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162978</th>\n",
       "      <td>there big project came into india modi dream p...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>big project came india modi dream project happ...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.889, 'pos': 0.111, 'comp...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.8, 'pos': 0.2, 'compound...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162979</th>\n",
       "      <td>have you ever listen about like gurukul where ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ever listen like gurukul discipline maintained...</td>\n",
       "      <td>{'neg': 0.159, 'neu': 0.703, 'pos': 0.138, 'co...</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>{'neg': 0.223, 'neu': 0.576, 'pos': 0.201, 'co...</td>\n",
       "      <td>0.450000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>162969 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  score  \\\n",
       "0       when modi promised “minimum government maximum...   -1.0   \n",
       "1       talk all the nonsense and continue all the dra...    0.0   \n",
       "2       what did just say vote for modi  welcome bjp t...    1.0   \n",
       "3       asking his supporters prefix chowkidar their n...    1.0   \n",
       "4       answer who among these the most powerful world...    1.0   \n",
       "...                                                   ...    ...   \n",
       "162975  why these 456 crores paid neerav modi not reco...   -1.0   \n",
       "162976  dear rss terrorist payal gawar what about modi...   -1.0   \n",
       "162977  did you cover her interaction forum where she ...    0.0   \n",
       "162978  there big project came into india modi dream p...    0.0   \n",
       "162979  have you ever listen about like gurukul where ...    1.0   \n",
       "\n",
       "                                           processed_text  \\\n",
       "0       modi promised “ minimum government maximum gov...   \n",
       "1                  talk nonsense continue drama vote modi   \n",
       "2       say vote modi welcome bjp told rahul main camp...   \n",
       "3       asking supporter prefix chowkidar name modi gr...   \n",
       "4       answer among powerful world leader today trump...   \n",
       "...                                                   ...   \n",
       "162975  456 crore paid neerav modi recovered congress ...   \n",
       "162976  dear r terrorist payal gawar modi killing 1000...   \n",
       "162977                       cover interaction forum left   \n",
       "162978  big project came india modi dream project happ...   \n",
       "162979  ever listen like gurukul discipline maintained...   \n",
       "\n",
       "                                           nltk_sentiment  spacy_sentiment  \\\n",
       "0       {'neg': 0.065, 'neu': 0.781, 'pos': 0.154, 'co...        -0.300000   \n",
       "1       {'neg': 0.184, 'neu': 0.816, 'pos': 0.0, 'comp...         0.000000   \n",
       "2       {'neg': 0.0, 'neu': 0.772, 'pos': 0.228, 'comp...         0.483333   \n",
       "3       {'neg': 0.187, 'neu': 0.655, 'pos': 0.158, 'co...         0.150000   \n",
       "4       {'neg': 0.0, 'neu': 0.808, 'pos': 0.192, 'comp...         0.400000   \n",
       "...                                                   ...              ...   \n",
       "162975  {'neg': 0.081, 'neu': 0.919, 'pos': 0.0, 'comp...        -0.291667   \n",
       "162976  {'neg': 0.398, 'neu': 0.491, 'pos': 0.111, 'co...        -0.195833   \n",
       "162977  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...         0.000000   \n",
       "162978  {'neg': 0.0, 'neu': 0.889, 'pos': 0.111, 'comp...         0.000000   \n",
       "162979  {'neg': 0.159, 'neu': 0.703, 'pos': 0.138, 'co...         0.350000   \n",
       "\n",
       "                                 processed_nltk_sentiment  \\\n",
       "0       {'neg': 0.095, 'neu': 0.682, 'pos': 0.223, 'co...   \n",
       "1       {'neg': 0.351, 'neu': 0.649, 'pos': 0.0, 'comp...   \n",
       "2       {'neg': 0.0, 'neu': 0.651, 'pos': 0.349, 'comp...   \n",
       "3       {'neg': 0.219, 'neu': 0.479, 'pos': 0.301, 'co...   \n",
       "4       {'neg': 0.0, 'neu': 0.763, 'pos': 0.237, 'comp...   \n",
       "...                                                   ...   \n",
       "162975  {'neg': 0.104, 'neu': 0.896, 'pos': 0.0, 'comp...   \n",
       "162976  {'neg': 0.435, 'neu': 0.443, 'pos': 0.123, 'co...   \n",
       "162977  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...   \n",
       "162978  {'neg': 0.0, 'neu': 0.8, 'pos': 0.2, 'compound...   \n",
       "162979  {'neg': 0.223, 'neu': 0.576, 'pos': 0.201, 'co...   \n",
       "\n",
       "        processed_spacy_sentiment  \n",
       "0                       -0.300000  \n",
       "1                        0.000000  \n",
       "2                        0.483333  \n",
       "3                        0.033333  \n",
       "4                        0.300000  \n",
       "...                           ...  \n",
       "162975                  -0.291667  \n",
       "162976                  -0.246875  \n",
       "162977                   0.000000  \n",
       "162978                   0.000000  \n",
       "162979                   0.450000  \n",
       "\n",
       "[162969 rows x 7 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_data[\"nltk_sentiment\"] = twitter_data[\"text\"].apply(get_nltk_sentiment, analyzer=analyzer)\n",
    "twitter_data[\"spacy_sentiment\"] = twitter_data[\"text\"].apply(get_spacy_sentiment, en_nlp=en_nlp)\n",
    "\n",
    "twitter_data[\"processed_nltk_sentiment\"] = twitter_data[\"processed_text\"].apply(get_nltk_sentiment, analyzer=analyzer)\n",
    "twitter_data[\"processed_spacy_sentiment\"] = twitter_data[\"processed_text\"].apply(get_spacy_sentiment, en_nlp=en_nlp)\n",
    "\n",
    "twitter_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.0, 'neu': 0.519, 'pos': 0.481, 'compound': 0.5719}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "vader_analyzer = SentimentIntensityAnalyzer()\n",
    "def get_vader_sentiment(text, analyzer):\n",
    "    vs = analyzer.polarity_scores(text)\n",
    "    return vs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_data[\"processed_vader_sentiment\"] = twitter_data[\"processed_text\"].apply(get_vader_sentiment, analyzer=vader_analyzer)\n",
    "twitter_data[\"vader_sentiment\"] = twitter_data[\"text\"].apply(get_vader_sentiment, analyzer=vader_analyzer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize(nltk_output):\n",
    "    if nltk_output[\"neu\"] > 1:\n",
    "        return 0\n",
    "    else:\n",
    "        return nltk_output[\"compound\"]\n",
    "    # pos = nltk_output[\"pos\"]\n",
    "    # neg = nltk_output[\"neg\"]\n",
    "    # neu = nltk_output[\"neu\"]\n",
    "    # max_v = max(pos, neg, neu) \n",
    "    # if max_v == pos:\n",
    "    #     return 1\n",
    "    # elif max_v == neg:\n",
    "    #     return -1\n",
    "    # else:\n",
    "    #     return 0\n",
    "\n",
    "\n",
    "def calculation_nltk_helper(actual, output, acc):\n",
    "    diff = abs(output[\"compound\"] - actual)\n",
    "    acc[\"rmse\"] += diff**2\n",
    "    acc[\"mae\"] += diff\n",
    "    output_pred = categorize(output)\n",
    "    if actual == 0:\n",
    "        acc[\"neu_total\"] += 1\n",
    "        if output_pred == 0:\n",
    "            acc[\"neu_correct\"] += 1\n",
    "    elif actual > 0:\n",
    "        acc[\"pos_total\"] += 1\n",
    "        if output_pred > 0:\n",
    "            acc[\"pos_correct\"] += 1\n",
    "    else:\n",
    "        acc[\"neg_total\"] += 1\n",
    "        if output_pred < 0:\n",
    "            acc[\"neg_correct\"] += 1\n",
    "\n",
    "def calculation_spacy_helper(actual, output, acc):\n",
    "    diff = abs(output - actual)\n",
    "    acc[\"rmse\"] += diff**2\n",
    "    acc[\"mae\"] += diff\n",
    "    if actual == 0:\n",
    "        acc[\"neu_total\"] += 1\n",
    "        if output == 0:\n",
    "            acc[\"neu_correct\"] += 1\n",
    "    elif actual > 0:\n",
    "        acc[\"pos_total\"] += 1\n",
    "        if output > 0:\n",
    "            acc[\"pos_correct\"] += 1\n",
    "    else:\n",
    "        acc[\"neg_total\"] += 1\n",
    "        if output < 0:\n",
    "            acc[\"neg_correct\"] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc_dict():\n",
    "    d = dict()\n",
    "    d[\"rmse\"] = 0\n",
    "    d[\"mae\"] = 0\n",
    "    d[\"pos_correct\"] = 0\n",
    "    d[\"neg_correct\"] = 0\n",
    "    d[\"neu_correct\"] = 0\n",
    "    d[\"pos_total\"] = 0\n",
    "    d[\"neg_total\"] = 0\n",
    "    d[\"neu_total\"] = 0\n",
    "    return d\n",
    "proc_spacy = acc_dict()\n",
    "proc_nltk = acc_dict()\n",
    "proc_vader = acc_dict()\n",
    "spacy = acc_dict()\n",
    "nltk = acc_dict()\n",
    "vader = acc_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         None\n",
       "1         None\n",
       "2         None\n",
       "3         None\n",
       "4         None\n",
       "          ... \n",
       "162975    None\n",
       "162976    None\n",
       "162977    None\n",
       "162978    None\n",
       "162979    None\n",
       "Length: 162969, dtype: object"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_data.apply(lambda row: calculation_nltk_helper(row[\"score\"], row[\"nltk_sentiment\"], nltk), axis=1)\n",
    "twitter_data.apply(lambda row: calculation_spacy_helper(row[\"score\"], row[\"spacy_sentiment\"], spacy), axis=1)\n",
    "twitter_data.apply(lambda row: calculation_nltk_helper(row[\"score\"], row[\"processed_nltk_sentiment\"], proc_nltk), axis=1)\n",
    "twitter_data.apply(lambda row: calculation_spacy_helper(row[\"score\"], row[\"processed_spacy_sentiment\"], proc_spacy), axis=1)\n",
    "twitter_data.apply(lambda row: calculation_nltk_helper(row[\"score\"], row[\"vader_sentiment\"], vader), axis=1)\n",
    "twitter_data.apply(lambda row: calculation_nltk_helper(row[\"score\"], row[\"processed_vader_sentiment\"], proc_vader), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nltk results\n",
      "rmse: 301.9313320406593,  mae: 93184.80140000037\n",
      "positive accuracy: 0.6814, negative accuracy: 0.6119, neutral accuracy: 0.3976\n",
      "\n",
      "spacy results\n",
      "rmse: 248.42326391163456,  mae: 78161.65319124197\n",
      "positive accuracy: 1.0, negative accuracy: 1.0, neutral accuracy: 1.0\n",
      "\n",
      "vader results\n",
      "rmse: 345.0173840142655,  mae: 118321.56489996763\n",
      "positive accuracy: 1.0, negative accuracy: 0.0, neutral accuracy: 0.0\n",
      "\n",
      "processed nltk results\n",
      "rmse: 301.61753802366593,  mae: 93147.5429000006\n",
      "positive accuracy: 0.6932, negative accuracy: 0.6041, neutral accuracy: 0.3941\n",
      "\n",
      "processed spacy results\n",
      "rmse: 254.60815454285597,  mae: 79542.31454811925\n",
      "positive accuracy: 0.9092, negative accuracy: 0.8754, neutral accuracy: 0.9708\n",
      "\n",
      "processed vader results\n",
      "rmse: 345.0173840142655,  mae: 118321.56489996763\n",
      "positive accuracy: 1.0, negative accuracy: 0.0, neutral accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "def print_res(d):\n",
    "    print(f'rmse: {math.sqrt(d[\"rmse\"])},  mae: {d[\"mae\"]}')\n",
    "    print(f'positive accuracy: {round(d[\"pos_correct\"] / d[\"pos_total\"], 4)}, negative accuracy: {round(d[\"neg_correct\"] / d[\"neg_total\"], 4)}, neutral accuracy: {round(d[\"neu_correct\"] / d[\"neu_total\"], 4)}')\n",
    "\n",
    "\n",
    "print(\"nltk results\")\n",
    "print_res(nltk)\n",
    "print(\"\")\n",
    "print(\"spacy results\")\n",
    "print_res(spacy)\n",
    "print(\"\")\n",
    "print(\"vader results\")\n",
    "print_res(vader)\n",
    "print(\"\")\n",
    "print(\"processed nltk results\")\n",
    "print_res(proc_nltk)\n",
    "print(\"\")\n",
    "print(\"processed spacy results\")\n",
    "print_res(proc_spacy)\n",
    "print(\"\")\n",
    "print(\"processed vader results\")\n",
    "print_res(proc_vader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
