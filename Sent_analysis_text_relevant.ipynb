{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import zipfile\n",
    "import json\n",
    "import io\n",
    "import spacy\n",
    "import csv\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## s3 host to access data from UMIACS\n",
    "s3_host = 'https://obj.umiacs.umd.edu'\n",
    "access_key_id = \"xxxxx\"\n",
    "secret_access_key = \"xxxxx\"\n",
    "\n",
    "s3 = boto3.client('s3', \n",
    "                  endpoint_url=s3_host, \n",
    "                  aws_access_key_id=access_key_id, \n",
    "                  aws_secret_access_key=secret_access_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## relevant substrings related to BRI Projects from the entities we identified\n",
    "## https://docs.google.com/document/d/1yoPZqhQqdBlaHAKHMbO3QpRmJVN1WLX8tmDwZ6sVDm0/edit\n",
    "\n",
    "relevant_PHL_substrings = {\"wawa\", \"clark\", \"subic\", \"powerplant\", \"pulangi\", \"negros\", \"snrdp\", \"national road\", \"development project\", \n",
    "                           \"rockwell\", \"estrella\", \"batangas\", \"phase 8\", \"ncr\", \"bss\", \"biopower\", \"biomass\", \"pnoc\", \"pv park\", \"meralco\"\n",
    "                            \"marawi\", \"mapanuepe\", \"manila\", \"railway\", \"hydropower\", \"isabela\", \"power plant\", \"fdc\", \"diduyon\", \"global city\",\n",
    "                            \"luzon\", \"Bukidnon\", \"bgc\", \"bonifacio global city\", \"origas\", \"binondo\",\"banaoang\", \"angat\", \"amburayan\", \"agus\", \n",
    "                            \"agno river\", \"8a\", \"kauswagan\", \"kaliwa\",\"general santos\", \"expressway\", \"chico river\", \"calaca\", \"bukidnon\", \n",
    "                            \"bonifacio\"}\n",
    "relevant_MLS_substrings = {\"4b\", \"edra\", \"tnb\", \"kedah\", \"sungai\", \"siput\", \"south china sea\", \"malacca\", \"corridor\",\"east coast\", \"railway link\", \n",
    "                           \"ecrl\", \"rembau\", \"penang\", \"sapangar\", \"samalaju\", \"pv park\", \"pantai\", \"murum\", \"malacca\", \"power plant\", \n",
    "                           \"industrial park\", \"biopower\", \"kuantan\", \"muda\", \"kota\", \"rapid transit\", \"klang\", \"wharf\", \"ppp\", \"kemaman port\", \n",
    "                           \"jimah\", \"gemas\", \"johor\", \"dungun\", \"bintulu\", \"baleh\", \"bakun\", \"machang\"}\n",
    "relevant_IDN_substrings = {\"power plant\", \"sulawesi\", \"teluk sirih\", \"tayan\", \"riau\", \"awar\",\"takalar\", \"suralaya\", \"madura\", \"sumatra\", \"sumsel\",\n",
    "                           \"sulawesi\", \"sulut\", \"kertosono\", \"rembang\", \"pelabuhan\", \"ratu\", \"parit\", \"baru\", \"kalimantan\", \"pangkalan\", \"susu\",\n",
    "                           \"paiton\", \"pacitan\", \"morowali\", \"industrial park\", \"aceh\", \"epc\", \"nagan\", \"raya\", \"power station\", \"manado\", \n",
    "                           \"road project\", \"lontar\", \"labuan\", \"angin\", \"kayan\", \"hydropower\", \"kalbar\", \"kalimantan\", \"jeneponto\", \"jatigede\",\n",
    "                           \"jakarta\", \"speed railway\", \"ppp\", \"bandung\", \"toll road section\", \"gunturharjo\", \"indramayu\", \"cilacap\", \"bali\", \n",
    "                           \"kalimantan\", \"batang\", \"baten\", \"serang\", \"banjarsari\", \"balikpapan\", \"adipala\"}\n",
    "# relevant_substrings_combined = [relevant_PHL_substrings, relevant_MLS_substrings, relevant_IDN_substrings]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## helper method to look for substrings from a certain set in a given text\n",
    "def look_for_substrings(relevant_substrings_set, tweet, project_country):\n",
    "    ## data in the format of: tweet-id, includes-project-substring, tweet-text, tweet-language, project-country\n",
    "    data = []\n",
    "    for substring in relevant_substrings_set:\n",
    "        raw_text = tweet[\"tweet_text\"]\n",
    "        if type(raw_text) != str:   ## one entry that has \"nan\" as the tweet text\n",
    "            raw_text = str(raw_text)\n",
    "        if substring in raw_text:\n",
    "            row = (tweet[\"tweet_id\"], substring, raw_text, tweet[\"tweet_language\"], project_country)\n",
    "            data.append(row)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## processes tmrc dataset\n",
    "def process_tmrc(folder_prefix):\n",
    "    ## we will collect the data with a list then create df at the end (most efficient with runtime)\n",
    "    data = []\n",
    "    response = s3.list_objects_v2(Bucket=\"twitter.tmrc\", Prefix=folder_prefix)\n",
    "    files = []\n",
    "    ## collect all the filenames to be processed \n",
    "    for obj in response.get('Contents', []):\n",
    "        object_key = obj['Key']\n",
    "        if object_key.endswith('.zip'):\n",
    "            files.append(object_key)\n",
    "    ##  process each file\n",
    "    for file in files:\n",
    "        zip_object = s3.get_object(Bucket=\"twitter.tmrc\", Key=file)\n",
    "        zip_contents = zip_object['Body'].read()\n",
    "        zip_file = zipfile.ZipFile(io.BytesIO(zip_contents), 'r')\n",
    "        for file_info in zip_file.infolist():\n",
    "            with zip_file.open(file_info) as json_file:\n",
    "                file_name = file_info.filename                    \n",
    "                ## we are only interested in the tweet file\n",
    "                if not file_name.endswith(\"-tweet.json\"):\n",
    "                    continue\n",
    "                try:\n",
    "                    json_data = json_file.read().decode('utf-8')\n",
    "                except: \n",
    "                    print(\"this is a text file\")\n",
    "                parsed_data = json.loads(json_data)\n",
    "                for ind_data in parsed_data:\n",
    "                    tweet = ind_data[\"tweet\"]\n",
    "                    data.extend(look_for_substrings(relevant_PHL_substrings, tweet, \"PHL\"))\n",
    "                    data.extend(look_for_substrings(relevant_IDN_substrings, tweet, \"IDN\"))\n",
    "                    data.extend(look_for_substrings(relevant_MLS_substrings, tweet, \"MLS\"))\n",
    "\n",
    "                    # for camp_substr in relevant_substrings_combined:\n",
    "                    #     data.extend(look_for_substrings(camp_substr, tweet, ))\n",
    "                    # lang = ind_data['tweet']['tweet_language'] \n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getdf_twitterei(file):\n",
    "    zip_object = s3.get_object(Bucket='twitter.ei', Key=file)\n",
    "    zip_contents = zip_object['Body'].read()\n",
    "    zip_file = zipfile.ZipFile(io.BytesIO(zip_contents), 'r')\n",
    "    for file_info in zip_file.infolist():\n",
    "        with zip_file.open(file_info) as csv_file:\n",
    "            df = None\n",
    "            try:\n",
    "                if df == None:\n",
    "                    df = pd.read_csv(csv_file)\n",
    "                else:\n",
    "                    df = pd.concat([df, pd.read_csv(csv_file)], axis=0)\n",
    "            except:\n",
    "                print(f\"{csv_file.filename} is not a csv file\")\n",
    "    df[\"tweet_id\"] = df[\"tweetid\"]\n",
    "    return df[[\"tweet_id\", \"tweet_language\", \"tweet_text\"]]\n",
    "\n",
    "def process_twitterei(df):\n",
    "    acc = []\n",
    "    df.apply(lambda row: process_row(row, acc), axis=1)\n",
    "    return acc\n",
    "\n",
    "def process_row(row, acc):\n",
    "    acc.extend(look_for_substrings(relevant_PHL_substrings, row, \"PHL\"))\n",
    "    acc.extend(look_for_substrings(relevant_IDN_substrings, row, \"IDN\"))\n",
    "    acc.extend(look_for_substrings(relevant_MLS_substrings, row, \"MLS\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmrc_folder_prefix_lst = ['August_2022/TMRC14_APAC_1/', \n",
    "                          'August_2022/TMRC14_APAC_2/', \n",
    "                          'October_2022/TMRC15_APAC_3/']\n",
    "twitterei_folder_prefix_lst = [\"2019_08/china_082019_1/china_082019_1_tweets_csv_unhashed.zip\",\n",
    "                               \"2019_08/china_082019_2/china_082019_2_tweets_csv_unhashed.zip\",\n",
    "                               \"2019_08/china_082019_3/china_082019_3_tweets_csv_unhashed.zip\",\n",
    "                               \"2020_05/china_052020/china_052020_tweets_csv_unhashed.zip\", \n",
    "                               \"2020_09/thailand_092020/thailand_092020_tweets_csv_unhashed.zip\"]\n",
    "\n",
    "## this dict will be in the format of campaign_name, data\n",
    "campaign_data_dict = dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TMRC14_APAC_1\n",
      "TMRC14_APAC_2\n",
      "TMRC15_APAC_3\n",
      "china_082019_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/r4/sgr1zrxx0038xwsxj6n3k8900000gn/T/ipykernel_39325/1549733038.py:10: DtypeWarning: Columns (6,30) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "china_082019_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/r4/sgr1zrxx0038xwsxj6n3k8900000gn/T/ipykernel_39325/1549733038.py:10: DtypeWarning: Columns (30) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "china_082019_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/r4/sgr1zrxx0038xwsxj6n3k8900000gn/T/ipykernel_39325/1549733038.py:10: DtypeWarning: Columns (30) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_file)\n",
      "/var/folders/r4/sgr1zrxx0038xwsxj6n3k8900000gn/T/ipykernel_39325/1549733038.py:10: DtypeWarning: Columns (30) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "china_052020\n",
      "thailand_092020\n"
     ]
    }
   ],
   "source": [
    "for f in tmrc_folder_prefix_lst:\n",
    "    name = f.split('/')[1]\n",
    "    print(name)\n",
    "    campaign_data_dict[name] = process_tmrc(f)\n",
    "\n",
    "\n",
    "for f in twitterei_folder_prefix_lst:\n",
    "    name = f.split('/')[1]\n",
    "    print(name)\n",
    "    df = getdf_twitterei(f)\n",
    "    campaign_data_dict[name] = process_twitterei(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>project_substring</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>tweet_language</th>\n",
       "      <th>project_country</th>\n",
       "      <th>CampaignID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1387933360429748225</td>\n",
       "      <td>muda</td>\n",
       "      <td>Munarman telah diciduk ini lah dukungan dri an...</td>\n",
       "      <td>in</td>\n",
       "      <td>MLS</td>\n",
       "      <td>TMRC14_APAC_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1366595382596149248</td>\n",
       "      <td>baru</td>\n",
       "      <td>RT @radenrauf: Apa yang bikin kamu gampang ilf...</td>\n",
       "      <td>in</td>\n",
       "      <td>IDN</td>\n",
       "      <td>TMRC14_APAC_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1379423796357001218</td>\n",
       "      <td>angat</td>\n",
       "      <td>tegakan #HukumHRS jangan biarkan bebas provoka...</td>\n",
       "      <td>in</td>\n",
       "      <td>PHL</td>\n",
       "      <td>TMRC14_APAC_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1382310663410774021</td>\n",
       "      <td>baru</td>\n",
       "      <td>Rendahkan Martabat peradilan, Rizieq Shihab di...</td>\n",
       "      <td>in</td>\n",
       "      <td>IDN</td>\n",
       "      <td>TMRC14_APAC_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1383295471058259970</td>\n",
       "      <td>baru</td>\n",
       "      <td>Terbukti nyata bhw pemrintah terbuka terhdp ma...</td>\n",
       "      <td>in</td>\n",
       "      <td>IDN</td>\n",
       "      <td>TMRC14_APAC_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198836</th>\n",
       "      <td>1215191677482127360</td>\n",
       "      <td>8a</td>\n",
       "      <td>#เมียหลวงบวกเมียน้อย https://t.co/IWZW7tp8aa</td>\n",
       "      <td>und</td>\n",
       "      <td>PHL</td>\n",
       "      <td>thailand_092020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198837</th>\n",
       "      <td>1227491832889634817</td>\n",
       "      <td>8a</td>\n",
       "      <td>#ผบทบต้องลาออก แล้วเสรีรวมไอซ์ทำไมไม่ออก 555 h...</td>\n",
       "      <td>th</td>\n",
       "      <td>PHL</td>\n",
       "      <td>thailand_092020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198838</th>\n",
       "      <td>1192277843427749888</td>\n",
       "      <td>raya</td>\n",
       "      <td>น้ำตาคนลำพระยา จ.ยะลา\\n#Savelampraya #Saveyala...</td>\n",
       "      <td>th</td>\n",
       "      <td>IDN</td>\n",
       "      <td>thailand_092020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198839</th>\n",
       "      <td>1197394755228798976</td>\n",
       "      <td>8a</td>\n",
       "      <td>https://t.co/lomfgaqMyW https://t.co/8aAzjAXcJl</td>\n",
       "      <td>und</td>\n",
       "      <td>PHL</td>\n",
       "      <td>thailand_092020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198840</th>\n",
       "      <td>1204974579317268485</td>\n",
       "      <td>8a</td>\n",
       "      <td>ปฐมบทยุบอนาคตใหม่ https://t.co/8aXklcDeuV</td>\n",
       "      <td>th</td>\n",
       "      <td>PHL</td>\n",
       "      <td>thailand_092020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>198841 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   tweet_id project_substring  \\\n",
       "0       1387933360429748225              muda   \n",
       "1       1366595382596149248              baru   \n",
       "2       1379423796357001218             angat   \n",
       "3       1382310663410774021              baru   \n",
       "4       1383295471058259970              baru   \n",
       "...                     ...               ...   \n",
       "198836  1215191677482127360                8a   \n",
       "198837  1227491832889634817                8a   \n",
       "198838  1192277843427749888              raya   \n",
       "198839  1197394755228798976                8a   \n",
       "198840  1204974579317268485                8a   \n",
       "\n",
       "                                               tweet_text tweet_language  \\\n",
       "0       Munarman telah diciduk ini lah dukungan dri an...             in   \n",
       "1       RT @radenrauf: Apa yang bikin kamu gampang ilf...             in   \n",
       "2       tegakan #HukumHRS jangan biarkan bebas provoka...             in   \n",
       "3       Rendahkan Martabat peradilan, Rizieq Shihab di...             in   \n",
       "4       Terbukti nyata bhw pemrintah terbuka terhdp ma...             in   \n",
       "...                                                   ...            ...   \n",
       "198836       #เมียหลวงบวกเมียน้อย https://t.co/IWZW7tp8aa            und   \n",
       "198837  #ผบทบต้องลาออก แล้วเสรีรวมไอซ์ทำไมไม่ออก 555 h...             th   \n",
       "198838  น้ำตาคนลำพระยา จ.ยะลา\\n#Savelampraya #Saveyala...             th   \n",
       "198839    https://t.co/lomfgaqMyW https://t.co/8aAzjAXcJl            und   \n",
       "198840          ปฐมบทยุบอนาคตใหม่ https://t.co/8aXklcDeuV             th   \n",
       "\n",
       "       project_country       CampaignID  \n",
       "0                  MLS    TMRC14_APAC_1  \n",
       "1                  IDN    TMRC14_APAC_1  \n",
       "2                  PHL    TMRC14_APAC_1  \n",
       "3                  IDN    TMRC14_APAC_1  \n",
       "4                  IDN    TMRC14_APAC_1  \n",
       "...                ...              ...  \n",
       "198836             PHL  thailand_092020  \n",
       "198837             PHL  thailand_092020  \n",
       "198838             IDN  thailand_092020  \n",
       "198839             PHL  thailand_092020  \n",
       "198840             PHL  thailand_092020  \n",
       "\n",
       "[198841 rows x 6 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## turn dict into dataframe\n",
    "text_relevant_df = pd.DataFrame()\n",
    "for campaign, list in campaign_data_dict.items():\n",
    "    ## data in the format of: CampaignID, tweet-id, includes-project-substring, tweet-text, tweet-language, project-country\n",
    "        cur_df = pd.DataFrame(list)\n",
    "        cur_df.columns = ['tweet_id', 'project_substring', 'tweet_text', 'tweet_language', 'project_country']\n",
    "        cur_df[\"CampaignID\"] = campaign\n",
    "        text_relevant_df = pd.concat([text_relevant_df, cur_df], ignore_index=True)\n",
    "text_relevant_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_relevant_df.to_csv(\"~/Coding/buntain/sentiment_data/text_relevant_df.csv\", index=False)\n",
    "text_relevant_df.to_csv(\"~/Coding/buntain/sentiment_data/text_relevant_df.csv\", encoding='utf-8', quoting=csv.QUOTE_ALL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "project_substring\n",
       "bali      47871\n",
       "baru      47803\n",
       "ncr       10486\n",
       "awar       9707\n",
       "4b         8579\n",
       "angat      8445\n",
       "agus       8040\n",
       "8a         7754\n",
       "muda       7610\n",
       "angin      7410\n",
       "ratu       6182\n",
       "kota       4462\n",
       "penang     3410\n",
       "ppp        3040\n",
       "raya       2165\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_relevant_df[\"project_substring\"].value_counts().head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "project_country\n",
       "IDN    132084\n",
       "PHL     38378\n",
       "MLS     28379\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_relevant_df[\"project_country\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet_language\n",
       "in     144025\n",
       "en      22418\n",
       "zh       4597\n",
       "und      3290\n",
       "ar       2754\n",
       "pt       2574\n",
       "tl       1972\n",
       "es       1201\n",
       "id        483\n",
       "ko        291\n",
       "fr        262\n",
       "ja        220\n",
       "hi        206\n",
       "ht        188\n",
       "et        173\n",
       "nl        147\n",
       "tr        111\n",
       "th         92\n",
       "fa         91\n",
       "ro         86\n",
       "it         81\n",
       "pl         68\n",
       "no         66\n",
       "fi         64\n",
       "de         62\n",
       "cy         51\n",
       "eu         46\n",
       "da         37\n",
       "ur         36\n",
       "lt         33\n",
       "cs         33\n",
       "lv         30\n",
       "ru         28\n",
       "hu         27\n",
       "sv         24\n",
       "zxx        19\n",
       "ca         17\n",
       "sl         13\n",
       "is         12\n",
       "qme        11\n",
       "vi          9\n",
       "art         4\n",
       "hr          4\n",
       "bn          4\n",
       "sk          3\n",
       "qht         2\n",
       "qam         1\n",
       "mr          1\n",
       "bs          1\n",
       "ne          1\n",
       "bg          1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_relevant_df[\"tweet_language\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CampaignID\n",
       "china_082019_1     100410\n",
       "china_082019_3      60203\n",
       "china_082019_2      16910\n",
       "TMRC14_APAC_1        8435\n",
       "TMRC14_APAC_2        7915\n",
       "TMRC15_APAC_3        3271\n",
       "china_052020         1630\n",
       "thailand_092020        67\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_relevant_df[\"CampaignID\"].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
